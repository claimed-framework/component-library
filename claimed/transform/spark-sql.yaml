name: SparkSQL
description: Execute arbitrary SQL queries againts CSV and PARQUET files

inputs:
- {name: data_file, type: String, description: 'file name for CSV or PARQUET file - must end with .csv or .parquet (default: data.csv)'}
- {name: master, type: String, description: 'master url of spark master (default: local mode)'}
- {name: data_dir, type: String, description: 'data_dir temporal data storage for local execution (default: ../../data/)'}
- {name: sql, type: String, description: 'sql statement to execute, table name == df, example: select * from df'}


outputs:
- {name: output_result_file, type: String, description: 'name of resulting file (default: data_result.csv)'}


implementation:
    container:
        image: romeokienzler/claimed-SparkSQL:0.1
        command:
        - sh
        - -ec
        - |
          python ./spark-sql.py output_result_file="$0" data_file="$1" master="$2" data_dir="$3" sql="$4" 
        - {outputPath: output_result_file}
        - {inputValue: data_file}
        - {inputValue: master}
        - {inputValue: data_dir}
        - {inputValue: sql}
